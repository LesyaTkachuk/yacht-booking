import os
import pandas as pd
import numpy as np
from sklearn.neighbors import NearestNeighbors
from sklearn.preprocessing import StandardScaler
import pickle
from sqlalchemy import create_engine, text, bindparam
from sqlalchemy.dialects.postgresql import UUID, ARRAY
from tqdm import tqdm
import dotenv

dotenv.load_dotenv()

class YachtRecommender:
    
    def __init__(self, df: pd.DataFrame):
        self.df = df.copy()
        self.feature_matrix = None
        self.knn_model = None
        self.scaler = None
        self.yacht_id_to_idx = {}
        self.idx_to_yacht_id = {}
        
    def prepare_features(self):
        df = self.df.copy()
        
        numerical_features = ['guests', 'cabins', 'crew', 'length', 'year', 'rating']

        for col in numerical_features:
            df[col] = pd.to_numeric(df[col], errors='coerce')
            median_val = df[col].median()
            df[col] = df[col].fillna(median_val if pd.notna(median_val) else 0) # –ó–∞–ø–æ–≤–Ω—é—î–º–æ 0, —è–∫—â–æ –º–µ–¥—ñ–∞–Ω–∞ = NaN
        
        price_cols = ['summerLowSeasonPrice', 'summerHighSeasonPrice', 'winterLowSeasonPrice', 'winterHighSeasonPrice']
        for col in price_cols:
             df[col] = pd.to_numeric(df[col], errors='coerce')
            
        df['avg_price'] = df[price_cols].mean(axis=1, skipna=True)
        df['avg_price'] = df['avg_price'].fillna(df['avg_price'].median())
        df['log_price'] = np.log1p(df['avg_price'])
        
        type_dummies = pd.get_dummies(df['type'], prefix='type').astype(int)
        
        top_marinas = df['baseMarina'].value_counts().head(50).index 
        df['marina_grouped'] = df['baseMarina'].apply(
            lambda x: x if x in top_marinas else 'Other'
        )
        marina_dummies = pd.get_dummies(df['marina_grouped'], prefix='marina').astype(int)
        
        country_dummies = pd.get_dummies(df['country'], prefix='country').astype(int)
        
        feature_cols = numerical_features + ['log_price']
        
        numerical_df = df[feature_cols]
        
        feature_matrix = pd.concat([
            numerical_df,
            type_dummies,
            marina_dummies,
            country_dummies
        ], axis=1)
        
        feature_matrix = feature_matrix.fillna(0)
        
        print(f"‚úÖ Feature matrix —Å—Ç–≤–æ—Ä–µ–Ω–æ: {feature_matrix.shape}")
        print(f"   Numerical features: {len(feature_cols)}")
        print(f"   Type dummies: {type_dummies.shape[1]}")
        print(f"   Marina dummies: {marina_dummies.shape[1]}")
        print(f"   Country dummies: {country_dummies.shape[1]}")
        
        return feature_matrix
    
    def fit(self, n_neighbors=11, metric='cosine'):
        print(f"\nüîß –¢—Ä–µ–Ω—É–≤–∞–Ω–Ω—è KNN –º–æ–¥–µ–ª—ñ (n_neighbors={n_neighbors}, metric={metric})...")
        
        self.feature_matrix = self.prepare_features()
        
        self.scaler = StandardScaler()
        feature_matrix_scaled = self.scaler.fit_transform(self.feature_matrix.values)
        
        if 'id' in self.df.columns:
            self.yacht_id_to_idx = {yacht_id: idx for idx, yacht_id in enumerate(self.df['id'])}
            self.idx_to_yacht_id = {idx: yacht_id for yacht_id, idx in self.yacht_id_to_idx.items()}
        else:
            self.yacht_id_to_idx = {idx: idx for idx in range(len(self.df))}
            self.idx_to_yacht_id = self.yacht_id_to_idx
        
        self.knn_model = NearestNeighbors(
            n_neighbors=n_neighbors,
            metric=metric,
            algorithm='auto',
            n_jobs=-1
        )
        
        self.knn_model.fit(feature_matrix_scaled)
        
        print(f"‚úÖ KNN –º–æ–¥–µ–ª—å –Ω–∞—Ç—Ä–µ–Ω–æ–≤–∞–Ω–∞!")
        
        return self
    
    def recommend(self, yacht_id, top_k=10, filters=None):
        if self.knn_model is None:
            raise ValueError("–ú–æ–¥–µ–ª—å –Ω–µ –Ω–∞—Ç—Ä–µ–Ω–æ–≤–∞–Ω–∞! –°–ø–æ—á–∞—Ç–∫—É –≤–∏–∫–ª–∏—á—Ç–µ .fit()")
        
        if yacht_id not in self.yacht_id_to_idx:
            raise ValueError(f"Yacht ID {yacht_id} –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ –≤ –¥–∞—Ç–∞—Å–µ—Ç—ñ")
        
        yacht_idx = self.yacht_id_to_idx[yacht_id]
        
        yacht_feature_series = self.feature_matrix.iloc[yacht_idx]
        yacht_features = self.scaler.transform(yacht_feature_series.values.reshape(1, -1))
        
        distances, indices = self.knn_model.kneighbors(yacht_features)
        
        distances = distances[0][1:]
        indices = indices[0][1:]
        
        if self.knn_model.metric == 'cosine':
            similarities = 1 - distances
        else:
            max_dist = distances.max() if distances.max() > 0 else 1
            similarities = 1 - (distances / max_dist)
        
        recommendations = []
        for idx, similarity in zip(indices, similarities):
            yacht_data = self.df.iloc[idx].copy()
            yacht_data['similarity_score'] = similarity
            recommendations.append(yacht_data)
        
        recommendations_df = pd.DataFrame(recommendations)
        
        return recommendations_df.head(top_k)
    
    def save_model(self, filepath='similar_yachts.pkl'):
        with open(filepath, 'wb') as f:
            pickle.dump({
                'knn_model': self.knn_model,
                'feature_matrix': self.feature_matrix,
                'scaler': self.scaler,
                'yacht_id_to_idx': self.yacht_id_to_idx,
                'idx_to_yacht_id': self.idx_to_yacht_id,
                'df': self.df
            }, f)
        print(f"‚úÖ –ú–æ–¥–µ–ª—å –∑–±–µ—Ä–µ–∂–µ–Ω–∞ —É {filepath}")
    
    @classmethod
    def load_model(cls, filepath='similar_yachts.pkl'):
        with open(filepath, 'rb') as f:
            data = pickle.load(f)
        
        recommender = cls(data['df'])
        recommender.knn_model = data['knn_model']
        recommender.feature_matrix = data['feature_matrix']
        recommender.scaler = data['scaler']
        recommender.yacht_id_to_idx = data['yacht_id_to_idx']
        recommender.idx_to_yacht_id = data['idx_to_yacht_id']
        
        print(f"‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–∞ –∑ {filepath}")
        return recommender


if __name__ == "__main__":
    
    print("--- [Sim Yachts] –ü–æ—á–∞—Ç–æ–∫ –æ–Ω–æ–≤–ª–µ–Ω–Ω—è 'similarYachts' ---")
    print(os.getenv("DATABASE_USERNAME"))

    db_string = "postgresql+psycopg2://" + os.getenv("DATABASE_USERNAME") + ":" + os.getenv("DATABASE_PASSWORD") + "@" + os.getenv("DATABASE_HOST") + ":" + os.getenv("DATABASE_PORT") + "/" + os.getenv("DATABASE_NAME")
    if not db_string:
        print("‚ùå –ü–û–ú–ò–õ–ö–ê: –ó–º—ñ–Ω–Ω–∞ —Å–µ—Ä–µ–¥–æ–≤–∏—â–∞ DB_STRING –Ω–µ –≤—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞.")
        exit(1)
        
    engine = create_engine(db_string)
    query = "SELECT * FROM yachts;"
    
    try:
        raw_conn = engine.raw_connection()
        df = pd.read_sql(query, raw_conn)
    finally:
        raw_conn.close()
    
    print(f"–ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ {len(df)} —è—Ö—Ç –∑ –±–∞–∑–∏ –¥–∞–Ω–∏—Ö.")
    
    # (n_neighbors=12, —â–æ–± –æ—Ç—Ä–∏–º–∞—Ç–∏ 11 —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ–π + —Å–∞–º—É —è—Ö—Ç—É)
    recommender = YachtRecommender(df)
    recommender.fit(n_neighbors=13, metric='cosine')
    
    recommender.save_model('yacht_recommender.pkl')
    
    print("\nüöÄ –ü–æ—á–∏–Ω–∞—î–º–æ –≥–µ–Ω–µ—Ä–∞—Ü—ñ—é —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ–π –¥–ª—è –≤—Å—ñ—Ö —è—Ö—Ç...")
    
    all_recommendations_data = []
    all_yacht_ids = df['id'].unique()
    
    for yacht_id in tqdm(all_yacht_ids, desc="–ì–µ–Ω–µ—Ä–∞—Ü—ñ—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ–π"):
        try:
            recs_df = recommender.recommend(yacht_id, top_k=11)
            recs_ids = recs_df['id'].tolist()
            
            all_recommendations_data.append({
                'yacht_id': yacht_id,
                'similar_yachts': recs_ids
            })
        except ValueError as e:
            print(f"–ü–æ–º–∏–ª–∫–∞ –¥–ª—è yacht_id {yacht_id}: {e}")
            all_recommendations_data.append({
                'yacht_id': yacht_id,
                'similar_yachts': []
            })

    print(f"\n‚úÖ –£—Å–ø—ñ—à–Ω–æ –∑–≥–µ–Ω–µ—Ä–æ–≤–∞–Ω–æ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—ó –¥–ª—è {len(all_recommendations_data)} —è—Ö—Ç.")
    
    print(f"üì§ –û–Ω–æ–≤–ª—é—î–º–æ 'similarYachts' –≤ 'yachts' —Ç–∞–±–ª–∏—Ü—ñ...")
    
    update_query = text("""
        UPDATE yachts
        SET "similarYachts" = :recs
        WHERE id = :id
    """).bindparams(
        bindparam("recs", type_=ARRAY(UUID)),
        bindparam("id",   type_=UUID),
    )
    
    try:
        with engine.begin() as conn:
            for item in tqdm(all_recommendations_data, desc="–û–Ω–æ–≤–ª–µ–Ω–Ω—è –±–∞–∑–∏ –¥–∞–Ω–∏—Ö"):
                yacht_id = str(item['yacht_id'])
                recs = [str(r) for r in item['similar_yachts']]

                conn.execute(update_query, {
                    "id": yacht_id,
                    "recs": recs
                })

        print(f"‚úÖ –î–∞–Ω—ñ —É—Å–ø—ñ—à–Ω–æ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ –≤ 'yachts' —Ç–∞–±–ª–∏—Ü—é!")
        
    except Exception as e:
        print(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –ø—ñ–¥ —á–∞—Å –æ–Ω–æ–≤–ª–µ–Ω–Ω—è 'yachts' –≤ –±–∞–∑—ñ –¥–∞–Ω–∏—Ö: {e}")

    print("--- [Sim Yachts] –û–Ω–æ–≤–ª–µ–Ω–Ω—è 'similarYachts' –∑–∞–≤–µ—Ä—à–µ–Ω–æ ---")
